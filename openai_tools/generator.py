from typing import Optional, Dict, List, Any, Callable
import os
import functools
from dataclasses import dataclass
from copy import deepcopy
import yaml
from openai_tools import Client
from datetime import datetime, timezone
from pathlib import Path
import re

from .db import Client as DBClient


# Set a version number for the yaml now so we can provide an upgrade path later.
SERIALIZATION_VERSION = 1


class SkipTurnException(Exception):
    pass


class StopPlayingException(Exception):
    pass


class ShowMenuException(Exception):
    pass


@dataclass
class Turn:
    """ Represents one turn in a dialogue session."""
    name: str
    text: str


class Session:

    def __init__(self, actors: Dict[str, List[str]], contexts: List[str], turns=None,
                 override_settings: Optional[Dict[str, Any]] = None, scene_name='', api_key='', use_db=False):
        """
        Creates a dialogue session similar to the OpenAI playground chat preset. Turns can be generated by open AI or
        added directly (as when a human being is responding). Turns do not have to follow any specific order.

        Args:
            actors: The names of the people in the chat. It is used to setup the stop tokens.
            contexts: Some optional text describing the scenario or individuals in the chat. Very helpful for the AI.
            turns: Some optional turns to show the bot the formatting and setup the rest of the conversation along with
                   the context. New turns will be appended to this list.
            override_settings: Overrides the default settings which are taken from the chat preset in the OpenAI
                   playground.
            scene_name: A human friendly name for the scene. Will be used as the name when exporting.
            api_key: The OpenAI API key. Can use the environment var 'OPENAI_API_SECRET' instead.
            use_db: Should the requests and responses be saved locally to the tinymongo database for posterity.
        """
        self.actors = actors
        self.client = Client(api_key=os.environ.get('OPENAI_API_SECRET', api_key), default_engine='davinci')
        self.turns = turns
        self.contexts = contexts
        self.override_settings = override_settings
        self.current_prompt: str = ''
        self.scene_name: str = scene_name
        self.db: Optional[DBClient] = None

        # Instantiate the tinymongo database
        if use_db:
            self.db = DBClient()

        # Default settings from the chat preset in the OpenAI playground.
        self.base_settings = {
            'max_tokens': 150,
            'temperature': 0.9,
            'top_p': 1.0,
            'n': 1,
            'stream': False,
            'logprobs': 0,
        }

    def get_params(self):
        # Note: There is a 4 stop token limit unless you stream and do your own processing per @gdb.
        stops = {'stop': ['\n\n'] + [f'{name}:' for name in list(self.actors.keys())[:3]]}
        params = {**self.base_settings, **stops, **self.override_settings}
        return deepcopy(params)

    def choose_next_actor(self) -> str:
        options = ['MENU'] + list(self.actors.keys())
        for i, option in enumerate(options):
            print(f'{i}: {option}')
        while True:
            inpt = input(">>>> Who speaks next?")
            if not inpt.isnumeric():
                print("[Error: Invalid Selection]")
                continue

            choice = int(inpt)
            if not 0 <= choice < len(options):
                print("[Error: Invalid Selection]")
                continue

            if choice == 0:
                raise ShowMenuException()

            return options[choice]

    def add_actor(self, actor_name, details: List):
        assert actor_name not in self.actors
        self.actors[actor_name] = details

    def store_request_cb(self, uid_cb, parent_req_id, settings):
        if self.db:
            uid = self.db.request_add(settings, parent_uid=parent_req_id)
            if uid_cb:
                uid_cb(uid)
        return settings

    def generate_prompt(self, actors_active: List[str], next_actor: Optional[str] = None) -> str:

        # Start the prompt with the context.
        prompt = "\n".join(self.contexts) + "\n\n"

        # Add only the active actors to the scene.
        for actor in actors_active:
            assert actor in self.actors
            details = '\n'.join(['- ' + item for item in self.actors[actor]])
            prompt += f"Facts about {actor}:\n{details}\n\n"

        # Then add all the existing turns.
        for turn in self.turns:
            prompt += f"{turn.name}: {turn.text}\n"

        if next_actor:
            # Finally add the prompt for the current actor.
            assert next_actor in self.actors
            prompt += f"{next_actor}:"

        return prompt

    def choose_an_option_cb(self, req_id, turn_name: str, gen_response: Dict) -> Optional[str]:
        if self.db:
            self.db.response_add(req_id, gen_response)
        options = ['BACK']
        for option in gen_response['choices']:
            options.append(option['text'])
        options.append("MORE")

        while True:
            print('\n/=== OPTIONS ===/\n')
            output = "\n".join([f'{i}: {text.strip()}' for i, text in enumerate(options)]) + "\n\n"
            print(output)
            inpt = input(f"As {turn_name}, choose option or just type for custom response: ")

            if inpt.isnumeric():
                choice = int(inpt)

                if not 0 <= choice < len(options):
                    print("[ERROR: Invalid selection, try again]")
                    continue

                # BACK
                if choice == 0:
                    raise SkipTurnException()

                # MORE - should trigger a new set of options from GPT.
                if choice == len(options) - 1:
                    return None

                text = options[choice]
                print(f"CHOICE: {choice} -> {text}")
                return text
            elif len(inpt) > 0:
                return inpt

    def generate_request_settings(self, prompt) -> Dict[str, Any]:
        settings = self.get_params()
        settings['prompt'] = prompt
        return settings

    def generate_turn(self, actor_name, pre_gen_callback: Optional[Callable[[str, Dict], Optional[str]]] = None,
                      post_gen_callback: Optional[Callable[[str, Dict], Optional[str]]] = None) -> Optional[Turn]:
        """
        Generates a dialog turn in the chat.

        Args:
            actor_name: The individual to generate a turn for. Should already exist in the 'names' property before
                generating.
            pre_gen_callback: Optional callback that allows modifying the request before it's sent to openAI.
            post_gen_callback: Optional callback that takes the generated response and returns the string to use as the
                turn text or None to cancel the turn completely.

        Returns:
            A Turn() representing the name and their generated text.

        """

        self.current_prompt = self.generate_prompt(list(self.actors.keys()), actor_name)

        self.generate_request_settings(self.current_prompt)

        settings = self.generate_request_settings(self.current_prompt)

        # allow pre_gen_callback to observe and override any of the default settings on a request by request basis.
        settings = pre_gen_callback(settings) if pre_gen_callback else settings

        response = self.client.completions(**settings)

        # Allow the callback to provide it's own text or choose from multiple options.
        if post_gen_callback:
            text = post_gen_callback(response)
        else:
            # Otherwise we assume the first item in the list.
            assert len(response['choices']) > 0, "The list of choices returned from OpenAI was less than 1."
            text = response['choices'][0]['text']

        # If text ended up as None, consider it cancelled and don't continue to add it to the turn history.
        if text is None:
            return None
        else:
            assert type(text) == str
            text = text.strip()

        # Create a new Turn using the text provided.
        turn = Turn(actor_name, text)

        # Save the this turn so we can reuse it as prompt context on the next generation and return it.
        self.turns.append(turn)

        # Update the current prompt since we have a new Turn created. Useful for inspecting or dumping it later.
        self.current_prompt = self.generate_prompt(list(self.actors.keys()))
        return turn

    def show_menu_dialog(self):
        print("--== MAIN MENU ==--")
        options = ['QUIT', 'CONTINUE', 'ADD ACTOR']
        print("\n".join([f'{i}: {text}' for i, text in enumerate(options)]))
        inpt = ''
        while not inpt.isnumeric():
            inpt = input(">>>> choose:")
            if not inpt.isnumeric():
                print("[Error: Invalid selection]")
                continue
            choice = int(inpt)
            if not 0 <= choice < len(options):
                print("[Error: Invalid selection]")
                continue

            # QUIT
            if choice == 0:
                raise StopPlayingException()

            # CONTINUE
            if choice == 1:
                return

            # ADD ACTOR
            if choice == 2:
                self.show_add_actor_dialog()

    def show_add_actor_dialog(self):
        while True:
            inpt = input(">>>> Add the actor details like 'NAME: DESCRIPTION' or use 'q' to cancel:\n")
            if inpt == 'q':
                return
            items = inpt.split(':')
            if len(items) != 2:
                print("[Error: Couldn't parse input.]")
                continue
            self.add_actor(items[0], [items[1]])
            return

    def main_loop(self):
        parent_req_id = None
        self.current_prompt = self.generate_prompt(list(self.actors.keys()))
        while True:
            turn = None
            try:
                actor = self.choose_next_actor()
                while turn is None:
                    req_id = None

                    def update_req_id_cb(uid):
                        nonlocal req_id
                        nonlocal parent_req_id
                        assert uid is not None
                        req_id = parent_req_id = uid

                    pregen_callback = functools.partial(self.store_request_cb, update_req_id_cb, parent_req_id)
                    postgen_callback = lambda response: self.choose_an_option_cb(req_id, actor, response)
                    turn = self.generate_turn(actor, pregen_callback, postgen_callback)

            except SkipTurnException:
                continue

            except ShowMenuException:
                self.show_menu_dialog()
                continue

    @staticmethod
    def print_line(head, context):
        print(f'{head}: {context}\n')

    @staticmethod
    def load_from_yaml(stream):
        scene = yaml.safe_load(stream)
        assert scene.get('serialization_version') == SERIALIZATION_VERSION

        name = scene.get('scene', '')
        actors = scene.get('actors')
        contexts = scene.get('contexts')
        turns = []
        for turn in scene.get('turns', []):
            assert len(turn) == 1
            actor = list(turn)[0]
            turns.append(Turn(actor, turn[actor]))
        return name, actors, contexts, turns

    @staticmethod
    def dump_to_yaml(session: 'Session', stream):
        data = {
            'serialization_version': SERIALIZATION_VERSION,
            'scene': session.scene_name,
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'contexts': session.contexts,
            'actors': session.actors,
            'turns': [{turn.name: turn.text} for turn in session.turns]
        }
        yaml.safe_dump(data, stream, sort_keys=False)


def main(args):

    if args.save_folder:
        folder_path = Path(args.save_folder)
        assert folder_path.exists()
        assert folder_path.is_dir()

    if args.scene:
        print(f">>>> Loading scene from yaml {args.scene.name}..")
        name, actors, contexts, turns = Session.load_from_yaml(args.scene)

    else:
        print(f">>>> Using default blacksmith scene..")
        name = "Default scene"
        actors = {
            "Blacksmith": [
                "Impatient and wary of new customers, but is willing to work with anyone who has the money to pay and "
                "who specializes in high quality items."],
            "Adventurer": ["Has just come to town in search of slaying an ogre that lives in the hills beyond "
                           "the city."],
        }

        contexts = [
            "The following is a conversation is set in a fantasy world and is between a medieval Blacksmith and an "
            "Adventurer.",
        ]

        turns = [Turn("Adventurer", "* approaches the Blacksmith * Hello sir, I'm looking to purchase your strongest"
                                    " armor.")]

    engine = args.gpt_engine if args.gpt_engine else 'davinci'
    n = args.number_suggestions if args.number_suggestions else 5
    session = Session(actors, contexts, turns, scene_name=name, override_settings={
        'n': n,
        'engine': engine,
    })

    # print the starting context
    print(f"\nSCENE: {name}")
    print("\n".join(contexts))
    for actor in actors:
        print(f"{actor}:")
        for detail in actors[actor]:
            print(f"- {detail}")

    # print the starting turns
    for turn in turns:
        Session.print_line(turn.name, turn.text)

    try:
        session.main_loop()
    except StopPlayingException:

        if args.save_file:
            print(f">>>> Saving to {args.save_file.name} ")
            Session.dump_to_yaml(session, args.save_file)
        if args.save_folder:
            name = session.scene_name if session.scene_name else 'unnamed_session'
            datestr = datetime.now(timezone.utc).isoformat()
            filename = f'{name.lower()}__{datestr}'.replace(' ', '_')
            clean_filename = re.sub('[^0-9a-zA-Z]+', '-', filename) + '.yaml'
            path = Path(args.save_folder) / clean_filename
            print(f">>>> Saving to {path} ")
            with path.open('w') as f:
                Session.dump_to_yaml(session, f)
            print('..Done!')

        else:
            print("\n=======================")
            print("Here is your final transcript. Thanks for playing.")
            print("=======================")
            print(session.current_prompt)


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='Create a dialogue with GPT-3')

    parser.add_argument('--scene', type=argparse.FileType('r'), help="Load a scene yaml instead of using the default.")
    parser.add_argument('--save-file', type=argparse.FileType('w'), help="Saves the output to a specific file.")
    parser.add_argument('--enable-db', action='store_true', help="Store the requests and responses from OpenAI to a "
                                                                 "json database. Useful for posterity.")
    parser.add_argument('--save-folder', help="Save the final dialogue yaml into a folder.")
    parser.add_argument('--gpt-engine', help="The GPT-3 engine to use. Default: 'davinci'")
    parser.add_argument('--number-suggestions', type=int, help="How many options should be generated? NOTE: Uses "
                                                                     "more tokens.")

    _args = parser.parse_args()

    main(_args)
